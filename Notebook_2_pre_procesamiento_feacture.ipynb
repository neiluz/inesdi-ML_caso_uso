{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso de Uso: Detección de fraude en consumo energético"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fraude energético es un problema significativo para las compañías de electricidad, ya que genera pérdidas económicas, afecta la estabilidad del sistema y puede derivar en riesgos de seguridad. Muchas de estas irregularidades ocurren cuando los clientes manipulan sus medidores de electricidad o reportan consumos menores a los reales para pagar facturas más bajas.\n",
    "\n",
    "En este contexto, se requiere desarrollar un modelo de detección de fraude que permita identificar clientes con patrones de consumo anómalos y optimizar las inspecciones comerciales. Esto permitirá reducir costos operativos y mejorar la eficiencia en la identificación de fraudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "Objetivo del análisis El objetivo de este análisis es detectar clientes con alta probabilidad de fraude utilizando datos de consumo energético y características de facturación. Para ello, se analizarán patrones en los niveles de consumo, estados de los medidores y diferencias en las lecturas de los contadores. Se explorarán anomalías y se evaluará si ciertos comportamientos están asociados a casos de fraude.\n",
    "\n",
    "Los pasos clave del análisis incluyen:\n",
    "- Exploración de datos para entender patrones de consumo.\n",
    "- Identificación de valores atípicos en el consumo y diferencias de medición.\n",
    "- Análisis de fraude (target) y su relación con las variables disponibles.\n",
    "- Desarrollo de un modelo predictivo para clasificar clientes fraudulentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de los datasets\n",
    "\n",
    "1. **Dataset \"clients1_3.csv\"**: Contiene información sobre 135,493 clientes con las siguientes variables:\n",
    "- disrict: Código numérico del distrito (Integer)\n",
    "- client_id: Identificador único del cliente (String)\n",
    "- client_catg: Categoría del cliente (Integer)\n",
    "- region: Código de región geográfica (Integer)\n",
    "- creation_date: Fecha de alta del cliente (String, formato DD/MM/YYYY)\n",
    "- target: Variable objetivo donde 1.0 indica fraude y 0.0 indica no fraude (Float)\n",
    "\n",
    "2. **Dataset \"invoices1.csv\"**: Contiene 2,238,374 registros de facturación con información detallada:\n",
    "- client_id: Identificador del cliente que permite vincular con el dataset anterior\n",
    "- invoice_date: Fecha de emisión de la factura\n",
    "- tarif_type: Tipo de tarifa aplicada\n",
    "- counter_number: Número identificador del contador\n",
    "- counter_statue: Estado del contador\n",
    "- counter_code: Código del contador\n",
    "- reading_remarque: Observaciones sobre la lectura\n",
    "- counter_coefficient: Coeficiente utilizado para la medición\n",
    "- consommation_level_1,2,3,4: Niveles de consumo en diferentes franjas\n",
    "- old_index: Lectura anterior del contador\n",
    "- new_index: Lectura actual del contador\n",
    "- months_number: Número de meses incluidos en la factura\n",
    "- counter_type: Tipo de contador (ej. \"ELEC\" para electricidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Preprocesamiento y Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_invoice = '/home/ngonzalez/mi_pagina_personal/inesdi_ml/invoices.csv'\n",
    "file_cliente = '/home/ngonzalez/mi_pagina_personal/inesdi_ml/clients.csv'\n",
    "invoices_df = pd.read_csv(file_invoice)\n",
    "clients_df = pd.read_csv(file_cliente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2238374 entries, 0 to 2238373\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Dtype \n",
      "---  ------                ----- \n",
      " 0   Unnamed: 0            int64 \n",
      " 1   client_id             object\n",
      " 2   invoice_date          object\n",
      " 3   tarif_type            int64 \n",
      " 4   counter_number        int64 \n",
      " 5   counter_statue        object\n",
      " 6   counter_code          int64 \n",
      " 7   reading_remarque      int64 \n",
      " 8   counter_coefficient   int64 \n",
      " 9   consommation_level_1  int64 \n",
      " 10  consommation_level_2  int64 \n",
      " 11  consommation_level_3  int64 \n",
      " 12  consommation_level_4  int64 \n",
      " 13  old_index             int64 \n",
      " 14  new_index             int64 \n",
      " 15  months_number         int64 \n",
      " 16  counter_type          object\n",
      "dtypes: int64(13), object(4)\n",
      "memory usage: 290.3+ MB\n"
     ]
    }
   ],
   "source": [
    "invoices_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de invoices Contiene 2,238,374 registros y 17 columnas. La mayoría de las columnas son de tipo int64, excepto cuatro que son de tipo object: client_id, invoice_date, counter_statue y counter_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   disrict        135493 non-null  int64  \n",
      " 1   client_id      135493 non-null  object \n",
      " 2   client_catg    135493 non-null  int64  \n",
      " 3   region         135493 non-null  int64  \n",
      " 4   creation_date  135493 non-null  object \n",
      " 5   target         135493 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "clients_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El datatset de clientes Contiene 135,493 registros y 6 columnas. Mezcla tipos de datos int64, float64 y object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras filas del dataset de clientes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>train_Client_1</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>29/05/2002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>train_Client_10</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>13/03/1986</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>train_Client_100</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>11/07/1996</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>train_Client_1000</td>\n",
       "      <td>11</td>\n",
       "      <td>303</td>\n",
       "      <td>14/10/2014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disrict          client_id  client_catg  region creation_date  target\n",
       "0       60     train_Client_0           11     101    31/12/1994     0.0\n",
       "1       69     train_Client_1           11     107    29/05/2002     0.0\n",
       "2       62    train_Client_10           11     301    13/03/1986     0.0\n",
       "3       69   train_Client_100           11     105    11/07/1996     0.0\n",
       "4       62  train_Client_1000           11     303    14/10/2014     0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificación de las primeras filas\n",
    "print(\"\\nPrimeras filas del dataset de clientes:\")\n",
    "clients_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras filas del dataset de facturas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>client_id</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>counter_code</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1797067</td>\n",
       "      <td>train_Client_27015</td>\n",
       "      <td>2009-04-20</td>\n",
       "      <td>15</td>\n",
       "      <td>4051646</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25853</td>\n",
       "      <td>25853</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314893</td>\n",
       "      <td>train_Client_13786</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>40</td>\n",
       "      <td>6767497</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2432</td>\n",
       "      <td>2486</td>\n",
       "      <td>4</td>\n",
       "      <td>GAZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4234799</td>\n",
       "      <td>train_Client_93401</td>\n",
       "      <td>2008-11-20</td>\n",
       "      <td>40</td>\n",
       "      <td>6849486</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>GAZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2779039</td>\n",
       "      <td>train_Client_53889</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>11</td>\n",
       "      <td>622828</td>\n",
       "      <td>0</td>\n",
       "      <td>413</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11033</td>\n",
       "      <td>13266</td>\n",
       "      <td>8</td>\n",
       "      <td>ELEC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3484865</td>\n",
       "      <td>train_Client_73134</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>11</td>\n",
       "      <td>2165708268000</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>400</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "      <td>2672</td>\n",
       "      <td>4352</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           client_id invoice_date  tarif_type  counter_number  \\\n",
       "0     1797067  train_Client_27015   2009-04-20          15         4051646   \n",
       "1     1314893  train_Client_13786   2013-02-04          40         6767497   \n",
       "2     4234799  train_Client_93401   2008-11-20          40         6849486   \n",
       "3     2779039  train_Client_53889   2019-09-01          11          622828   \n",
       "4     3484865  train_Client_73134   2018-08-24          11   2165708268000   \n",
       "\n",
       "  counter_statue  counter_code  reading_remarque  counter_coefficient  \\\n",
       "0              0           202                 6                    1   \n",
       "1              0             5                 8                    1   \n",
       "2              0             5                 6                    1   \n",
       "3              0           413                 9                    1   \n",
       "4              0           203                 9                    1   \n",
       "\n",
       "   consommation_level_1  consommation_level_2  consommation_level_3  \\\n",
       "0                     0                     0                     0   \n",
       "1                    54                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                  1600                   633                     0   \n",
       "4                   800                   400                   480   \n",
       "\n",
       "   consommation_level_4  old_index  new_index  months_number counter_type  \n",
       "0                     0      25853      25853              4         ELEC  \n",
       "1                     0       2432       2486              4          GAZ  \n",
       "2                     0          0          0              4          GAZ  \n",
       "3                     0      11033      13266              8         ELEC  \n",
       "4                     0       2672       4352              4         ELEC  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nPrimeras filas del dataset de facturas:\")\n",
    "invoices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-Procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos en el dataset de clientes:\n",
      "disrict            int64\n",
      "client_id         object\n",
      "client_catg        int64\n",
      "region             int64\n",
      "creation_date     object\n",
      "target           float64\n",
      "dtype: object\n",
      "\n",
      "Tipos de datos en el dataset de facturas:\n",
      "Unnamed: 0               int64\n",
      "client_id               object\n",
      "invoice_date            object\n",
      "tarif_type               int64\n",
      "counter_number           int64\n",
      "counter_statue          object\n",
      "counter_code             int64\n",
      "reading_remarque         int64\n",
      "counter_coefficient      int64\n",
      "consommation_level_1     int64\n",
      "consommation_level_2     int64\n",
      "consommation_level_3     int64\n",
      "consommation_level_4     int64\n",
      "old_index                int64\n",
      "new_index                int64\n",
      "months_number            int64\n",
      "counter_type            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificación de tipos de datos\n",
    "print(\"\\nTipos de datos en el dataset de clientes:\")\n",
    "print(clients_df.dtypes)\n",
    "\n",
    "print(\"\\nTipos de datos en el dataset de facturas:\")\n",
    "print(invoices_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para detectar si una variable numérica es probablemente categórica\n",
    "def es_probablemente_categorica(serie):\n",
    "    \"\"\"\n",
    "    Determina si una variable numérica es probablemente categórica basándose en:\n",
    "    1. Número de valores únicos (cardinalidad)\n",
    "    2. Proporción de valores únicos respecto al total\n",
    "    3. Si todos los valores son enteros\n",
    "    \"\"\"\n",
    "    # Excluir nulos\n",
    "    serie = serie.dropna()\n",
    "    \n",
    "    # Si está vacía, no podemos determinar\n",
    "    if len(serie) == 0:\n",
    "        return False\n",
    "    \n",
    "    # Número de valores únicos\n",
    "    valores_unicos = serie.nunique()\n",
    "    \n",
    "    # Proporción de valores únicos\n",
    "    proporcion_unicos = valores_unicos / len(serie)\n",
    "    \n",
    "    # Verificar si todos los valores son enteros\n",
    "    todos_enteros = True\n",
    "    for x in serie.sample(min(1000, len(serie))):\n",
    "        if pd.notna(x):  # Verificar que no sea NaN\n",
    "            todos_enteros = todos_enteros and float(x).is_integer()\n",
    "    \n",
    "    # Criterios para considerar una variable como categórica\n",
    "    if todos_enteros and (valores_unicos <= 20 or proporcion_unicos < 0.05):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variables potencialmente categóricas en el dataset de clientes:\n",
      "- disrict: 4 valores únicos\n",
      "  Valores: [60, 62, 63, 69]\n",
      "- client_catg: 3 valores únicos\n",
      "  Valores: [11, 12, 51]\n",
      "- region: 25 valores únicos\n",
      "  Valores: [101, 103, 104, 105, 106, 107, 199, 206, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 371, 372, 379, 399]\n",
      "- target: 2 valores únicos\n",
      "  Valores: [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Analizar variables numéricas en ambos datasets\n",
    "print(\"\\nVariables potencialmente categóricas en el dataset de clientes:\")\n",
    "for col in clients_df.select_dtypes(include=['number']).columns:\n",
    "    if es_probablemente_categorica(clients_df[col]):\n",
    "        print(f\"- {col}: {clients_df[col].nunique()} valores únicos\")\n",
    "        print(f\"  Valores: {sorted(clients_df[col].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variables potencialmente categóricas en el dataset de facturas:\n",
      "- tarif_type: 17 valores únicos\n",
      "  Valores: [8, 9, 10, 11, 12, 13, 14, 15, 18, 21]...\n",
      "- counter_code: 41 valores únicos\n",
      "  Valores: [0, 5, 10, 16, 25, 40, 65, 101, 102, 201]...\n",
      "- reading_remarque: 7 valores únicos\n",
      "  Valores: [6, 7, 8, 9, 203, 207, 413]\n",
      "- counter_coefficient: 14 valores únicos\n",
      "  Valores: [0, 1, 2, 3, 4, 6, 8, 9, 10, 20]...\n",
      "- consommation_level_1: 6535 valores únicos\n",
      "  Valores: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]...\n",
      "- consommation_level_2: 9836 valores únicos\n",
      "  Valores: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]...\n",
      "- consommation_level_3: 1843 valores únicos\n",
      "  Valores: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]...\n",
      "- consommation_level_4: 9126 valores únicos\n",
      "  Valores: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]...\n",
      "- months_number: 760 valores únicos\n",
      "  Valores: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVariables potencialmente categóricas en el dataset de facturas:\")\n",
    "for col in invoices_df.select_dtypes(include=['number']).columns:\n",
    "    if es_probablemente_categorica(invoices_df[col]):\n",
    "        print(f\"- {col}: {invoices_df[col].nunique()} valores únicos\")\n",
    "        print(f\"  Valores: {sorted(invoices_df[col].unique())[:10]}{'...' if invoices_df[col].nunique() > 10 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convirtiendo variables numéricas categóricas a tipo categórico:\n",
      "- disrict convertida a tipo categórico\n",
      "- client_catg convertida a tipo categórico\n",
      "- region convertida a tipo categórico\n",
      "- target convertida a tipo categórico\n",
      "- tarif_type convertida a tipo categórico\n",
      "- counter_statue convertida a tipo categórico\n",
      "- counter_code convertida a tipo categórico\n",
      "- reading_remarque convertida a tipo categórico\n"
     ]
    }
   ],
   "source": [
    "# Convertir variables numéricas que son categóricas\n",
    "print(\"\\nConvirtiendo variables numéricas categóricas a tipo categórico:\")\n",
    "\n",
    "# Lista de variables a convertir en dataset de clientes\n",
    "cat_cols_clients = ['disrict', 'client_catg', 'region', 'target']\n",
    "for col in cat_cols_clients:\n",
    "    if col in clients_df.columns:\n",
    "        clients_df[col] = clients_df[col].astype('category')\n",
    "        print(f\"- {col} convertida a tipo categórico\")\n",
    "\n",
    "# Lista de variables a convertir en dataset de facturas\n",
    "cat_cols_invoices = ['tarif_type', 'counter_statue', 'counter_code', 'reading_remarque']\n",
    "for col in cat_cols_invoices:\n",
    "    if col in invoices_df.columns:\n",
    "        invoices_df[col] = invoices_df[col].astype('category')\n",
    "        print(f\"- {col} convertida a tipo categórico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos en el dataset de clientes:\n",
      "No hay valores nulos\n",
      "\n",
      "Valores nulos en el dataset de facturas:\n",
      "No hay valores nulos\n"
     ]
    }
   ],
   "source": [
    "# Verificación de valores nulos\n",
    "print(\"\\nValores nulos en el dataset de clientes:\")\n",
    "null_clients = clients_df.isnull().sum()\n",
    "print(null_clients[null_clients > 0] if null_clients.any() > 0 else \"No hay valores nulos\")\n",
    "\n",
    "print(\"\\nValores nulos en el dataset de facturas:\")\n",
    "null_invoices = invoices_df.isnull().sum()\n",
    "print(null_invoices[null_invoices > 0] if null_invoices.any() > 0 else \"No hay valores nulos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convirtiendo fechas a formato datetime:\n",
      "- creation_date tiene 0 valores nulos después de conversión\n",
      "- invoice_date tiene 0 valores nulos después de conversión\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConvirtiendo fechas a formato datetime:\")\n",
    "clients_df['creation_date'] = pd.to_datetime(clients_df['creation_date'], format='%d/%m/%Y', errors='coerce')\n",
    "invoices_df['invoice_date'] = pd.to_datetime(invoices_df['invoice_date'], errors='coerce')\n",
    "\n",
    "# Verificar conversión\n",
    "print(f\"- creation_date tiene {clients_df['creation_date'].isnull().sum()} valores nulos después de conversión\")\n",
    "print(f\"- invoice_date tiene {invoices_df['invoice_date'].isnull().sum()} valores nulos después de conversión\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de outliers sin imputación ni recorte:\n",
      "\n",
      "consommation_level_1:\n",
      "- Estadísticas básicas: min=0, q1=79.0, mediana=274.0, q3=600.0, max=126118\n",
      "- Rango intercuartílico (IQR): 521.0\n",
      "- Límites para detección de outliers: [-702.50, 1381.50]\n",
      "- Outliers por debajo del límite: 0 (0.00%)\n",
      "- Outliers por encima del límite: 62192 (2.78%)\n",
      "- Total outliers: 62192 (2.78%)\n",
      "\n",
      "consommation_level_2:\n",
      "- Estadísticas básicas: min=0, q1=0.0, mediana=0.0, q3=0.0, max=819886\n",
      "- Rango intercuartílico (IQR): 0.0\n",
      "- Límites para detección de outliers: [0.00, 0.00]\n",
      "- Outliers por debajo del límite: 0 (0.00%)\n",
      "- Outliers por encima del límite: 330860 (14.78%)\n",
      "- Total outliers: 330860 (14.78%)\n",
      "- Valores cero: 1907514 (85.22% del total)\n",
      "- Estadísticas para valores no cero (n=330860):\n",
      "  min=1, mediana=369.0, max=819886\n",
      "\n",
      "consommation_level_3:\n",
      "- Estadísticas básicas: min=0, q1=0.0, mediana=0.0, q3=0.0, max=36273\n",
      "- Rango intercuartílico (IQR): 0.0\n",
      "- Límites para detección de outliers: [0.00, 0.00]\n",
      "- Outliers por debajo del límite: 0 (0.00%)\n",
      "- Outliers por encima del límite: 91703 (4.10%)\n",
      "- Total outliers: 91703 (4.10%)\n",
      "- Valores cero: 2146671 (95.90% del total)\n",
      "- Estadísticas para valores no cero (n=91703):\n",
      "  min=1, mediana=396.0, max=36273\n",
      "\n",
      "consommation_level_4:\n",
      "- Estadísticas básicas: min=0, q1=0.0, mediana=0.0, q3=0.0, max=343568\n",
      "- Rango intercuartílico (IQR): 0.0\n",
      "- Límites para detección de outliers: [0.00, 0.00]\n",
      "- Outliers por debajo del límite: 0 (0.00%)\n",
      "- Outliers por encima del límite: 46403 (2.07%)\n",
      "- Total outliers: 46403 (2.07%)\n",
      "- Valores cero: 2191971 (97.93% del total)\n",
      "- Estadísticas para valores no cero (n=46403):\n",
      "  min=1, mediana=1150.0, max=343568\n",
      "\n",
      "old_index:\n",
      "- Estadísticas básicas: min=0, q1=1792.0, mediana=7689.0, q3=21653.0, max=2800280\n",
      "- Rango intercuartílico (IQR): 19861.0\n",
      "- Límites para detección de outliers: [-27999.50, 51444.50]\n",
      "- Outliers por debajo del límite: 0 (0.00%)\n",
      "- Outliers por encima del límite: 134541 (6.01%)\n",
      "- Total outliers: 134541 (6.01%)\n",
      "\n",
      "new_index:\n",
      "- Estadísticas básicas: min=0, q1=2059.0, mediana=8190.0, q3=22341.0, max=2870972\n",
      "- Rango intercuartílico (IQR): 20282.0\n",
      "- Límites para detección de outliers: [-28364.00, 52764.00]\n",
      "- Outliers por debajo del límite: 0 (0.00%)\n",
      "- Outliers por encima del límite: 133728 (5.97%)\n",
      "- Total outliers: 133728 (5.97%)\n"
     ]
    }
   ],
   "source": [
    "# Variables de consumo para analizar outliers\n",
    "consumo_cols = ['consommation_level_1', 'consommation_level_2', 'consommation_level_3', \n",
    "                'consommation_level_4', 'old_index', 'new_index']\n",
    "\n",
    "# Análisis de outliers sin tratamiento\n",
    "print(\"Análisis de outliers sin imputación ni recorte:\")\n",
    "for col in consumo_cols:\n",
    "    if col in invoices_df.columns:\n",
    "        # Calcular estadísticas descriptivas\n",
    "        stats = invoices_df[col].describe()\n",
    "        \n",
    "        # Calcular IQR y límites\n",
    "        q1 = stats['25%']\n",
    "        q3 = stats['75%']\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        \n",
    "        # Identificar outliers sin modificarlos\n",
    "        outliers_lower = (invoices_df[col] < lower_bound)\n",
    "        outliers_upper = (invoices_df[col] > upper_bound)\n",
    "        total_outliers_lower = outliers_lower.sum()\n",
    "        total_outliers_upper = outliers_upper.sum()\n",
    "        total_outliers = total_outliers_lower + total_outliers_upper\n",
    "        \n",
    "        # Calcular porcentajes\n",
    "        count_no_null = invoices_df[col].count()\n",
    "        pct_outliers_lower = (total_outliers_lower / count_no_null) * 100\n",
    "        pct_outliers_upper = (total_outliers_upper / count_no_null) * 100\n",
    "        pct_outliers_total = (total_outliers / count_no_null) * 100\n",
    "        \n",
    "        # Valores extremos\n",
    "        min_val = invoices_df[col].min()\n",
    "        max_val = invoices_df[col].max()\n",
    "        \n",
    "        # Reportar resultados\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"- Estadísticas básicas: min={min_val}, q1={q1}, mediana={stats['50%']}, q3={q3}, max={max_val}\")\n",
    "        print(f\"- Rango intercuartílico (IQR): {iqr}\")\n",
    "        print(f\"- Límites para detección de outliers: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        print(f\"- Outliers por debajo del límite: {total_outliers_lower} ({pct_outliers_lower:.2f}%)\")\n",
    "        print(f\"- Outliers por encima del límite: {total_outliers_upper} ({pct_outliers_upper:.2f}%)\")\n",
    "        print(f\"- Total outliers: {total_outliers} ({pct_outliers_total:.2f}%)\")\n",
    "        \n",
    "        # Para niveles 2-4, mostrar información adicional si hay muchos ceros\n",
    "        if 'consommation_level' in col and col != 'consommation_level_1':\n",
    "            zeros = (invoices_df[col] == 0).sum()\n",
    "            pct_zeros = (zeros / count_no_null) * 100\n",
    "            print(f\"- Valores cero: {zeros} ({pct_zeros:.2f}% del total)\")\n",
    "            \n",
    "            # Si hay muchos ceros, mostrar estadísticas para valores no cero\n",
    "            if pct_zeros > 50:\n",
    "                no_zeros = invoices_df[invoices_df[col] > 0][col]\n",
    "                if len(no_zeros) > 0:\n",
    "                    print(f\"- Estadísticas para valores no cero (n={len(no_zeros)}):\")\n",
    "                    print(f\"  min={no_zeros.min()}, mediana={no_zeros.median()}, max={no_zeros.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Facturas con diferencia extremadamente alta entre índices: 109855 (4.91%)\n"
     ]
    }
   ],
   "source": [
    "# Calcular diferencia entre índices\n",
    "invoices_df['diff_index'] = invoices_df['new_index'] - invoices_df['old_index']\n",
    "\n",
    "# Identificar diferencias extremas\n",
    "q3_diff = invoices_df['diff_index'].quantile(0.75)\n",
    "upper_bound_diff = q3_diff * 3\n",
    "invoices_df['extreme_diff'] = (invoices_df['diff_index'] > upper_bound_diff).astype(int)\n",
    "\n",
    "print(f\"\\nFacturas con diferencia extremadamente alta entre índices: {invoices_df['extreme_diff'].sum()} ({invoices_df['extreme_diff'].mean()*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PREPARACIÓN INICIAL\n",
    "# Calcular consumo total para cada factura\n",
    "invoices_df['consumo_total'] = (\n",
    "    invoices_df['consommation_level_1'].fillna(0) + \n",
    "    invoices_df['consommation_level_2'].fillna(0) + \n",
    "    invoices_df['consommation_level_3'].fillna(0) + \n",
    "    invoices_df['consommation_level_4'].fillna(0)\n",
    ")\n",
    "\n",
    "# Calcular diferencia entre índices\n",
    "invoices_df['diff_indices'] = invoices_df['new_index'] - invoices_df['old_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. AGREGACIÓN DE FACTURAS POR CLIENTE\n",
    "# Definir funciones de agregación\n",
    "agg_functions = {\n",
    "    'invoice_date': ['count'],\n",
    "    'months_number': ['sum'],\n",
    "    'consumo_total': ['sum', 'mean', 'std'],\n",
    "    'diff_indices': ['mean', 'std'],\n",
    "    'old_index': ['min', 'max'],\n",
    "    'new_index': ['min', 'max']\n",
    "}\n",
    "\n",
    "# Agregar por cliente\n",
    "fact_por_cliente = invoices_df.groupby('client_id').agg(agg_functions)\n",
    "\n",
    "# Aplanar columnas multindice\n",
    "fact_por_cliente.columns = ['_'.join(col).strip('_') for col in fact_por_cliente.columns]\n",
    "\n",
    "# Renombrar para claridad\n",
    "fact_por_cliente = fact_por_cliente.rename(columns={\n",
    "    'invoice_date_count': 'total_facturas',\n",
    "    'months_number_sum': 'meses_totales',\n",
    "    'consumo_total_sum': 'consumo_total',\n",
    "    'consumo_total_mean': 'consumo_promedio',\n",
    "    'consumo_total_std': 'variabilidad_consumo',\n",
    "    'diff_indices_mean': 'promedio_diferencia_indices'\n",
    "})\n",
    "\n",
    "# Calcular consumo mensual\n",
    "fact_por_cliente['consumo_mensual'] = fact_por_cliente['consumo_total'] / fact_por_cliente['meses_totales']\n",
    "fact_por_cliente['consumo_mensual'] = fact_por_cliente['consumo_mensual'].replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. VARIABLES TEMPORALES\n",
    "# Calcular antigüedad\n",
    "reference_date = pd.Timestamp('2020-01-01')\n",
    "clients_df['antiguedad_anios'] = (reference_date - clients_df['creation_date']).dt.days / 365.25\n",
    "\n",
    "# Extraer año de creación\n",
    "clients_df['creation_year'] = clients_df['creation_date'].dt.year\n",
    "\n",
    "# Crear cohortes temporales\n",
    "year_bins = [1975, 1985, 1995, 2005, 2015, 2025]\n",
    "clients_df['cohorte'] = pd.cut(clients_df['creation_year'], bins=year_bins, \n",
    "                             labels=['1975-1984', '1985-1994', '1995-2004', '2005-2014', '2015+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectando inconsistencias técnicas para todos los clientes...\n",
      "(Este proceso puede tomar tiempo)\n",
      "Procesando cliente 1/130867 (0.0%)...\n",
      "Procesando cliente 1001/130867 (0.8%)...\n",
      "Procesando cliente 2001/130867 (1.5%)...\n",
      "Procesando cliente 3001/130867 (2.3%)...\n",
      "Procesando cliente 4001/130867 (3.1%)...\n",
      "Procesando cliente 5001/130867 (3.8%)...\n",
      "Procesando cliente 6001/130867 (4.6%)...\n",
      "Procesando cliente 7001/130867 (5.3%)...\n",
      "Procesando cliente 8001/130867 (6.1%)...\n",
      "Procesando cliente 9001/130867 (6.9%)...\n",
      "Procesando cliente 10001/130867 (7.6%)...\n",
      "Procesando cliente 11001/130867 (8.4%)...\n",
      "Procesando cliente 12001/130867 (9.2%)...\n",
      "Procesando cliente 13001/130867 (9.9%)...\n",
      "Procesando cliente 14001/130867 (10.7%)...\n",
      "Procesando cliente 15001/130867 (11.5%)...\n",
      "Procesando cliente 16001/130867 (12.2%)...\n",
      "Procesando cliente 17001/130867 (13.0%)...\n",
      "Procesando cliente 18001/130867 (13.8%)...\n",
      "Procesando cliente 19001/130867 (14.5%)...\n",
      "Procesando cliente 20001/130867 (15.3%)...\n",
      "Procesando cliente 21001/130867 (16.0%)...\n",
      "Procesando cliente 22001/130867 (16.8%)...\n",
      "Procesando cliente 23001/130867 (17.6%)...\n",
      "Procesando cliente 24001/130867 (18.3%)...\n",
      "Procesando cliente 25001/130867 (19.1%)...\n",
      "Procesando cliente 26001/130867 (19.9%)...\n",
      "Procesando cliente 27001/130867 (20.6%)...\n",
      "Procesando cliente 28001/130867 (21.4%)...\n",
      "Procesando cliente 29001/130867 (22.2%)...\n",
      "Procesando cliente 30001/130867 (22.9%)...\n",
      "Procesando cliente 31001/130867 (23.7%)...\n",
      "Procesando cliente 32001/130867 (24.5%)...\n",
      "Procesando cliente 33001/130867 (25.2%)...\n",
      "Procesando cliente 34001/130867 (26.0%)...\n",
      "Procesando cliente 35001/130867 (26.7%)...\n",
      "Procesando cliente 36001/130867 (27.5%)...\n",
      "Procesando cliente 37001/130867 (28.3%)...\n",
      "Procesando cliente 38001/130867 (29.0%)...\n",
      "Procesando cliente 39001/130867 (29.8%)...\n",
      "Procesando cliente 40001/130867 (30.6%)...\n",
      "Procesando cliente 41001/130867 (31.3%)...\n",
      "Procesando cliente 42001/130867 (32.1%)...\n",
      "Procesando cliente 43001/130867 (32.9%)...\n",
      "Procesando cliente 44001/130867 (33.6%)...\n",
      "Procesando cliente 45001/130867 (34.4%)...\n",
      "Procesando cliente 46001/130867 (35.2%)...\n",
      "Procesando cliente 47001/130867 (35.9%)...\n",
      "Procesando cliente 48001/130867 (36.7%)...\n",
      "Procesando cliente 49001/130867 (37.4%)...\n",
      "Procesando cliente 50001/130867 (38.2%)...\n",
      "Procesando cliente 51001/130867 (39.0%)...\n",
      "Procesando cliente 52001/130867 (39.7%)...\n",
      "Procesando cliente 53001/130867 (40.5%)...\n",
      "Procesando cliente 54001/130867 (41.3%)...\n",
      "Procesando cliente 55001/130867 (42.0%)...\n",
      "Procesando cliente 56001/130867 (42.8%)...\n",
      "Procesando cliente 57001/130867 (43.6%)...\n",
      "Procesando cliente 58001/130867 (44.3%)...\n",
      "Procesando cliente 59001/130867 (45.1%)...\n",
      "Procesando cliente 60001/130867 (45.8%)...\n",
      "Procesando cliente 61001/130867 (46.6%)...\n",
      "Procesando cliente 62001/130867 (47.4%)...\n",
      "Procesando cliente 63001/130867 (48.1%)...\n",
      "Procesando cliente 64001/130867 (48.9%)...\n",
      "Procesando cliente 65001/130867 (49.7%)...\n",
      "Procesando cliente 66001/130867 (50.4%)...\n",
      "Procesando cliente 67001/130867 (51.2%)...\n",
      "Procesando cliente 68001/130867 (52.0%)...\n",
      "Procesando cliente 69001/130867 (52.7%)...\n",
      "Procesando cliente 70001/130867 (53.5%)...\n",
      "Procesando cliente 71001/130867 (54.3%)...\n",
      "Procesando cliente 72001/130867 (55.0%)...\n",
      "Procesando cliente 73001/130867 (55.8%)...\n",
      "Procesando cliente 74001/130867 (56.5%)...\n",
      "Procesando cliente 75001/130867 (57.3%)...\n",
      "Procesando cliente 76001/130867 (58.1%)...\n",
      "Procesando cliente 77001/130867 (58.8%)...\n",
      "Procesando cliente 78001/130867 (59.6%)...\n",
      "Procesando cliente 79001/130867 (60.4%)...\n",
      "Procesando cliente 80001/130867 (61.1%)...\n",
      "Procesando cliente 81001/130867 (61.9%)...\n",
      "Procesando cliente 82001/130867 (62.7%)...\n",
      "Procesando cliente 83001/130867 (63.4%)...\n",
      "Procesando cliente 84001/130867 (64.2%)...\n",
      "Procesando cliente 85001/130867 (65.0%)...\n",
      "Procesando cliente 86001/130867 (65.7%)...\n",
      "Procesando cliente 87001/130867 (66.5%)...\n",
      "Procesando cliente 88001/130867 (67.2%)...\n",
      "Procesando cliente 89001/130867 (68.0%)...\n",
      "Procesando cliente 90001/130867 (68.8%)...\n",
      "Procesando cliente 91001/130867 (69.5%)...\n",
      "Procesando cliente 92001/130867 (70.3%)...\n",
      "Procesando cliente 93001/130867 (71.1%)...\n",
      "Procesando cliente 94001/130867 (71.8%)...\n",
      "Procesando cliente 95001/130867 (72.6%)...\n",
      "Procesando cliente 96001/130867 (73.4%)...\n",
      "Procesando cliente 97001/130867 (74.1%)...\n",
      "Procesando cliente 98001/130867 (74.9%)...\n",
      "Procesando cliente 99001/130867 (75.7%)...\n",
      "Procesando cliente 100001/130867 (76.4%)...\n",
      "Procesando cliente 101001/130867 (77.2%)...\n",
      "Procesando cliente 102001/130867 (77.9%)...\n",
      "Procesando cliente 103001/130867 (78.7%)...\n",
      "Procesando cliente 104001/130867 (79.5%)...\n",
      "Procesando cliente 105001/130867 (80.2%)...\n",
      "Procesando cliente 106001/130867 (81.0%)...\n",
      "Procesando cliente 107001/130867 (81.8%)...\n",
      "Procesando cliente 108001/130867 (82.5%)...\n",
      "Procesando cliente 109001/130867 (83.3%)...\n",
      "Procesando cliente 110001/130867 (84.1%)...\n",
      "Procesando cliente 111001/130867 (84.8%)...\n",
      "Procesando cliente 112001/130867 (85.6%)...\n",
      "Procesando cliente 113001/130867 (86.3%)...\n",
      "Procesando cliente 114001/130867 (87.1%)...\n",
      "Procesando cliente 115001/130867 (87.9%)...\n",
      "Procesando cliente 116001/130867 (88.6%)...\n",
      "Procesando cliente 117001/130867 (89.4%)...\n",
      "Procesando cliente 118001/130867 (90.2%)...\n",
      "Procesando cliente 119001/130867 (90.9%)...\n",
      "Procesando cliente 120001/130867 (91.7%)...\n",
      "Procesando cliente 121001/130867 (92.5%)...\n",
      "Procesando cliente 122001/130867 (93.2%)...\n",
      "Procesando cliente 123001/130867 (94.0%)...\n",
      "Procesando cliente 124001/130867 (94.8%)...\n",
      "Procesando cliente 125001/130867 (95.5%)...\n",
      "Procesando cliente 126001/130867 (96.3%)...\n",
      "Procesando cliente 127001/130867 (97.0%)...\n",
      "Procesando cliente 128001/130867 (97.8%)...\n",
      "Procesando cliente 129001/130867 (98.6%)...\n",
      "Procesando cliente 130001/130867 (99.3%)...\n",
      "Procesando cliente 130867/130867 (100.0%)...\n",
      "\n",
      "Valores nulos en las columnas de inconsistencias después de la unión:\n",
      "tiene_inconsistencias_tecnicas    0\n",
      "indices_negativos                 0\n",
      "indices_cero                      0\n",
      "dtype: int64\n",
      "\n",
      "Estadísticas finales de inconsistencias:\n",
      "- Total de clientes analizados: 130867\n",
      "- Clientes con inconsistencias técnicas: 3847 (2.94%)\n",
      "- Clientes con índices negativos: 968\n",
      "- Clientes con índices cero pero consumo: 2934\n"
     ]
    }
   ],
   "source": [
    "# 4. DETECCIÓN DE INCONSISTENCIAS TÉCNICAS PARA TODOS LOS CLIENTES\n",
    "print(\"Detectando inconsistencias técnicas para todos los clientes...\")\n",
    "print(\"(Este proceso puede tomar tiempo)\")\n",
    "\n",
    "# Definir función para detectar inconsistencias\n",
    "def detectar_inconsistencias_tecnicas(facturas_cliente):\n",
    "    if len(facturas_cliente) <= 1:\n",
    "        return {\n",
    "            'tiene_inconsistencias_tecnicas': 0,\n",
    "            'indices_negativos': 0,\n",
    "            'indices_cero': 0\n",
    "        }\n",
    "    \n",
    "    # Ordenar por fecha\n",
    "    facturas_cliente = facturas_cliente.sort_values('invoice_date')\n",
    "    \n",
    "    # Detectar inconsistencias\n",
    "    indices_negativos = (facturas_cliente['diff_indices'] < 0).any()\n",
    "    indices_cero = ((facturas_cliente['diff_indices'] == 0) & \n",
    "                   (facturas_cliente['consumo_total'] > 0)).any()\n",
    "    \n",
    "    return {\n",
    "        'tiene_inconsistencias_tecnicas': int(indices_negativos or indices_cero),\n",
    "        'indices_negativos': int(indices_negativos),\n",
    "        'indices_cero': int(indices_cero)\n",
    "    }\n",
    "\n",
    "# Obtener todos los client_id únicos de las facturas\n",
    "all_clients = invoices_df['client_id'].unique()\n",
    "total_clients = len(all_clients)\n",
    "\n",
    "# Detectar inconsistencias para cada cliente\n",
    "inconsistencias_dict = {}\n",
    "for i, client_id in enumerate(all_clients):\n",
    "    # Mostrar progreso cada 1000 clientes para no saturar la consola\n",
    "    if i % 1000 == 0 or i == total_clients - 1:\n",
    "        print(f\"Procesando cliente {i+1}/{total_clients} ({((i+1)/total_clients*100):.1f}%)...\")\n",
    "    \n",
    "    facturas_cliente = invoices_df[invoices_df['client_id'] == client_id]\n",
    "    if len(facturas_cliente) > 0:\n",
    "        inconsistencias_dict[client_id] = detectar_inconsistencias_tecnicas(facturas_cliente)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "inconsistencias_df = pd.DataFrame.from_dict(inconsistencias_dict, orient='index')\n",
    "\n",
    "# Unir con facturas por cliente\n",
    "fact_por_cliente = fact_por_cliente.join(inconsistencias_df, how='left')\n",
    "\n",
    "# Verificar si hay valores nulos después de la unión\n",
    "nulos = fact_por_cliente[['tiene_inconsistencias_tecnicas', 'indices_negativos', 'indices_cero']].isnull().sum()\n",
    "print(\"\\nValores nulos en las columnas de inconsistencias después de la unión:\")\n",
    "print(nulos)\n",
    "\n",
    "# Completar valores nulos (debería haber pocos o ninguno)\n",
    "for col in ['tiene_inconsistencias_tecnicas', 'indices_negativos', 'indices_cero']:\n",
    "    if col in fact_por_cliente.columns and fact_por_cliente[col].isnull().sum() > 0:\n",
    "        fact_por_cliente[col] = fact_por_cliente[col].fillna(0)\n",
    "        print(f\"- Completados {fact_por_cliente[col].isnull().sum()} valores nulos en {col}\")\n",
    "\n",
    "# Mostrar estadísticas sobre las inconsistencias\n",
    "total_con_inconsistencias = fact_por_cliente['tiene_inconsistencias_tecnicas'].sum()\n",
    "porcentaje = (total_con_inconsistencias / len(fact_por_cliente)) * 100\n",
    "\n",
    "print(f\"\\nEstadísticas finales de inconsistencias:\")\n",
    "print(f\"- Total de clientes analizados: {len(fact_por_cliente)}\")\n",
    "print(f\"- Clientes con inconsistencias técnicas: {total_con_inconsistencias} ({porcentaje:.2f}%)\")\n",
    "print(f\"- Clientes con índices negativos: {fact_por_cliente['indices_negativos'].sum()}\")\n",
    "print(f\"- Clientes con índices cero pero consumo: {fact_por_cliente['indices_cero'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de fraude global: 0.0558\n"
     ]
    }
   ],
   "source": [
    "# 5. VARIABLES GEOGRÁFICAS CONTEXTUALIZADAS\n",
    "# Convertir target a tipo numérico si está como categórica\n",
    "if clients_df['target'].dtype.name == 'category':\n",
    "    clients_df['target'] = clients_df['target'].astype(int)\n",
    "\n",
    "categorical_cols_clients = ['disrict', 'client_catg', 'region']  # Elimina 'target' de esta lista\n",
    "for col in categorical_cols_clients:\n",
    "    clients_df[col] = clients_df[col].astype('category')\n",
    "\n",
    "# Calcular tasa base de fraude\n",
    "fraude_base = clients_df['target'].mean()\n",
    "print(f\"Tasa de fraude global: {fraude_base:.4f}\")\n",
    "\n",
    "# Calcular tasas por región con regularización bayesiana\n",
    "region_counts = clients_df.groupby('region').size()\n",
    "region_fraud = clients_df.groupby('region')['target'].mean()\n",
    "alpha = 10  # Factor de regularización\n",
    "region_fraud_reg = (region_counts * region_fraud + alpha * fraude_base) / (region_counts + alpha)\n",
    "\n",
    "# Crear DataFrame para unir después\n",
    "region_df = pd.DataFrame({\n",
    "    'region': region_fraud_reg.index,\n",
    "    'tasa_fraude_reg': region_fraud_reg.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. NORMALIZACIÓN CONTEXTUALIZADA DE CONSUMO\n",
    "# Primero unir clientes con consumo mensual\n",
    "clients_with_consumption = clients_df[['client_id', 'region', 'cohorte']].copy()\n",
    "clients_with_consumption = clients_with_consumption.merge(\n",
    "    fact_por_cliente[['consumo_mensual']].reset_index(),\n",
    "    on='client_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Definir función para calcular percentiles por grupo\n",
    "def calcular_percentiles_por_grupo(df, grupo, variable):\n",
    "    result = {}\n",
    "    for nombre, grupo_df in df.groupby(grupo):\n",
    "        grupo_df = grupo_df.dropna(subset=[variable])\n",
    "        if len(grupo_df) > 10:  # Solo si hay suficientes datos\n",
    "            percentiles = {}\n",
    "            for p in [25, 50, 75, 90, 95]:\n",
    "                percentiles[p] = grupo_df[variable].quantile(p/100)\n",
    "            result[nombre] = percentiles\n",
    "    return result\n",
    "\n",
    "# Calcular percentiles por cohorte y región\n",
    "percentiles_cohorte = calcular_percentiles_por_grupo(clients_with_consumption, 'cohorte', 'consumo_mensual')\n",
    "percentiles_region = calcular_percentiles_por_grupo(clients_with_consumption, 'region', 'consumo_mensual')\n",
    "\n",
    "# Definir función para asignar nivel de consumo\n",
    "def asignar_nivel_consumo(consumo, grupo, percentiles_dict):\n",
    "    if grupo not in percentiles_dict or pd.isna(consumo):\n",
    "        return 'desconocido'\n",
    "    \n",
    "    percentiles = percentiles_dict[grupo]\n",
    "    if consumo <= percentiles[25]:\n",
    "        return 'bajo'\n",
    "    elif consumo <= percentiles[75]:\n",
    "        return 'normal'\n",
    "    elif consumo <= percentiles[95]:\n",
    "        return 'alto'\n",
    "    else:\n",
    "        return 'muy_alto'\n",
    "\n",
    "# Aplicar a cada cliente\n",
    "clients_with_consumption['nivel_consumo_cohorte'] = clients_with_consumption.apply(\n",
    "    lambda x: asignar_nivel_consumo(x['consumo_mensual'], x['cohorte'], percentiles_cohorte), axis=1\n",
    ")\n",
    "clients_with_consumption['nivel_consumo_region'] = clients_with_consumption.apply(\n",
    "    lambda x: asignar_nivel_consumo(x['consumo_mensual'], x['region'], percentiles_region), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final creado con 135493 filas y 27 columnas\n"
     ]
    }
   ],
   "source": [
    "# Unir clientes con facturas\n",
    "dataset_final = clients_df.merge(\n",
    "    fact_por_cliente.reset_index(), \n",
    "    left_on='client_id', \n",
    "    right_on='client_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Añadir tasa de fraude regularizada por región\n",
    "dataset_final = dataset_final.merge(\n",
    "    region_df, \n",
    "    on='region', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Añadir niveles de consumo contextualizados\n",
    "dataset_final = dataset_final.merge(\n",
    "    clients_with_consumption[['client_id', 'nivel_consumo_cohorte', 'nivel_consumo_region']],\n",
    "    on='client_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Manejar valores nulos\n",
    "for col in dataset_final.columns:\n",
    "    if col not in ['client_id', 'target', 'creation_date'] and dataset_final[col].isnull().sum() > 0:\n",
    "        if dataset_final[col].dtype in [np.float64, np.int64]:\n",
    "            dataset_final[col] = dataset_final[col].fillna(0)\n",
    "        elif dataset_final[col].dtype == 'category' or pd.api.types.is_object_dtype(dataset_final[col]):\n",
    "            dataset_final[col] = dataset_final[col].fillna('desconocido')\n",
    "\n",
    "print(f\"Dataset final creado con {dataset_final.shape[0]} filas y {dataset_final.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrict</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_catg</th>\n",
       "      <th>region</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>target</th>\n",
       "      <th>antiguedad_anios</th>\n",
       "      <th>creation_year</th>\n",
       "      <th>cohorte</th>\n",
       "      <th>total_facturas</th>\n",
       "      <th>...</th>\n",
       "      <th>old_index_max</th>\n",
       "      <th>new_index_min</th>\n",
       "      <th>new_index_max</th>\n",
       "      <th>consumo_mensual</th>\n",
       "      <th>tiene_inconsistencias_tecnicas</th>\n",
       "      <th>indices_negativos</th>\n",
       "      <th>indices_cero</th>\n",
       "      <th>tasa_fraude_reg</th>\n",
       "      <th>nivel_consumo_cohorte</th>\n",
       "      <th>nivel_consumo_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>25.002053</td>\n",
       "      <td>1994</td>\n",
       "      <td>1985-1994</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15066.0</td>\n",
       "      <td>3950.0</td>\n",
       "      <td>15638.0</td>\n",
       "      <td>94.986842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>train_Client_1</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>2002-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>17.593429</td>\n",
       "      <td>2002</td>\n",
       "      <td>1995-2004</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23264.0</td>\n",
       "      <td>5747.0</td>\n",
       "      <td>23590.0</td>\n",
       "      <td>126.097561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065803</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>train_Client_10</td>\n",
       "      <td>11</td>\n",
       "      <td>301</td>\n",
       "      <td>1986-03-13</td>\n",
       "      <td>0</td>\n",
       "      <td>33.804244</td>\n",
       "      <td>1986</td>\n",
       "      <td>1985-1994</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41532.0</td>\n",
       "      <td>29497.0</td>\n",
       "      <td>44614.0</td>\n",
       "      <td>141.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033029</td>\n",
       "      <td>alto</td>\n",
       "      <td>alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>train_Client_100</td>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>1996-07-11</td>\n",
       "      <td>0</td>\n",
       "      <td>23.474333</td>\n",
       "      <td>1996</td>\n",
       "      <td>1995-2004</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055927</td>\n",
       "      <td>bajo</td>\n",
       "      <td>bajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>train_Client_1000</td>\n",
       "      <td>11</td>\n",
       "      <td>303</td>\n",
       "      <td>2014-10-14</td>\n",
       "      <td>0</td>\n",
       "      <td>5.215606</td>\n",
       "      <td>2014</td>\n",
       "      <td>2005-2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13337.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>13729.0</td>\n",
       "      <td>247.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>alto</td>\n",
       "      <td>alto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  disrict          client_id client_catg region creation_date  target  \\\n",
       "0      60     train_Client_0          11    101    1994-12-31       0   \n",
       "1      69     train_Client_1          11    107    2002-05-29       0   \n",
       "2      62    train_Client_10          11    301    1986-03-13       0   \n",
       "3      69   train_Client_100          11    105    1996-07-11       0   \n",
       "4      62  train_Client_1000          11    303    2014-10-14       0   \n",
       "\n",
       "   antiguedad_anios  creation_year    cohorte  total_facturas  ...  \\\n",
       "0         25.002053           1994  1985-1994            17.0  ...   \n",
       "1         17.593429           2002  1995-2004            20.0  ...   \n",
       "2         33.804244           1986  1985-1994             8.0  ...   \n",
       "3         23.474333           1996  1995-2004            10.0  ...   \n",
       "4          5.215606           2014  2005-2014             8.0  ...   \n",
       "\n",
       "   old_index_max  new_index_min  new_index_max  consumo_mensual  \\\n",
       "0        15066.0         3950.0        15638.0        94.986842   \n",
       "1        23264.0         5747.0        23590.0       126.097561   \n",
       "2        41532.0        29497.0        44614.0       141.571429   \n",
       "3           99.0           90.0           99.0         0.190476   \n",
       "4        13337.0         1624.0        13729.0       247.100000   \n",
       "\n",
       "   tiene_inconsistencias_tecnicas  indices_negativos  indices_cero  \\\n",
       "0                             0.0                0.0           0.0   \n",
       "1                             0.0                0.0           0.0   \n",
       "2                             0.0                0.0           0.0   \n",
       "3                             0.0                0.0           0.0   \n",
       "4                             0.0                0.0           0.0   \n",
       "\n",
       "   tasa_fraude_reg  nivel_consumo_cohorte  nivel_consumo_region  \n",
       "0         0.035925                 normal                normal  \n",
       "1         0.065803                 normal                normal  \n",
       "2         0.033029                   alto                  alto  \n",
       "3         0.055927                   bajo                  bajo  \n",
       "4         0.054499                   alto                  alto  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135493 entries, 0 to 135492\n",
      "Data columns (total 27 columns):\n",
      " #   Column                          Non-Null Count   Dtype         \n",
      "---  ------                          --------------   -----         \n",
      " 0   disrict                         135493 non-null  category      \n",
      " 1   client_id                       135493 non-null  object        \n",
      " 2   client_catg                     135493 non-null  category      \n",
      " 3   region                          135493 non-null  category      \n",
      " 4   creation_date                   135493 non-null  datetime64[ns]\n",
      " 5   target                          135493 non-null  int64         \n",
      " 6   antiguedad_anios                135493 non-null  float64       \n",
      " 7   creation_year                   135493 non-null  int32         \n",
      " 8   cohorte                         135493 non-null  category      \n",
      " 9   total_facturas                  135493 non-null  float64       \n",
      " 10  meses_totales                   135493 non-null  float64       \n",
      " 11  consumo_total                   135493 non-null  float64       \n",
      " 12  consumo_promedio                135493 non-null  float64       \n",
      " 13  variabilidad_consumo            135493 non-null  float64       \n",
      " 14  promedio_diferencia_indices     135493 non-null  float64       \n",
      " 15  diff_indices_std                135493 non-null  float64       \n",
      " 16  old_index_min                   135493 non-null  float64       \n",
      " 17  old_index_max                   135493 non-null  float64       \n",
      " 18  new_index_min                   135493 non-null  float64       \n",
      " 19  new_index_max                   135493 non-null  float64       \n",
      " 20  consumo_mensual                 135493 non-null  float64       \n",
      " 21  tiene_inconsistencias_tecnicas  135493 non-null  float64       \n",
      " 22  indices_negativos               135493 non-null  float64       \n",
      " 23  indices_cero                    135493 non-null  float64       \n",
      " 24  tasa_fraude_reg                 135493 non-null  float64       \n",
      " 25  nivel_consumo_cohorte           135493 non-null  object        \n",
      " 26  nivel_consumo_region            135493 non-null  object        \n",
      "dtypes: category(4), datetime64[ns](1), float64(17), int32(1), int64(1), object(3)\n",
      "memory usage: 23.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final.to_csv('/home/ngonzalez/mi_pagina_personal/inesdi_ml/dataset_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y próximos pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook hemos completado el preprocesamiento y la ingeniería de características para la detección de fraude energético, con especial atención a minimizar posibles sesgos y maximizar el poder predictivo:\n",
    "\n",
    "**Preprocesamiento básico:**\n",
    "- Identificación y conversión de variables categóricas\n",
    "- Manejo de valores nulos\n",
    "- Conversión adecuada de fechas\n",
    "\n",
    "**Feature Engineering avanzado:**\n",
    "- Variables temporales contextualizadas (cohortes)\n",
    "- Variables geográficas con regularización bayesiana\n",
    "- Detección de inconsistencias técnicas objetivas\n",
    "- Normalización contextualizada del consumo\n",
    "\n",
    "**Variables derivadas clave:**\n",
    "\n",
    "- tasa_fraude_reg: Tasa regularizada por región\n",
    "- nivel_consumo_cohorte/region: Categorización contextualizada del consumo\n",
    "- tiene_inconsistencias_tecnicas: Detector de anomalías en lecturas\n",
    "- consumo_mensual: Medida objetiva de consumo normalizado\n",
    "\n",
    "**Dataset final preparado:**\n",
    "- 135,493 registros\n",
    "- 27 variables de alta calidad informativa\n",
    "- Combinación de datos categóricos y numéricos\n",
    "\n",
    "\n",
    "**Enfoque Metodológico**\n",
    "El enfoque ha priorizado:\n",
    "- Contextualización en lugar de etiquetado absoluto\n",
    "- Regularización bayesiana para áreas con pocos datos\n",
    "- Detección objetiva de anomalías técnicas\n",
    "- Categorización multinivel del consumo\n",
    "\n",
    "Este enfoque nos ha permitido crear un dataset robusto que captura tanto los aspectos técnicos como contextuales del fraude energético.\n",
    "\n",
    "**Próximos Pasos**\n",
    "Para completar el proyecto de detección de fraude, recomendamos:\n",
    "1. Transformación Final de Variables\n",
    "- Aplicar one-hot encoding a variables categóricas nominales (disrict, client_catg, region)\n",
    "- Considerar encoding ordinal para variables con orden natural (nivel_consumo_cohorte, nivel_consumo_region)\n",
    "- Analizar la distribución de variables numéricas y aplicar las transformaciones necesarias (normalización, escalado)\n",
    "\n",
    "2. Modelado Predictivo\n",
    "- Dividir los datos en conjuntos de entrenamiento, validación y prueba (70-15-15%)\n",
    "- Implementar y comparar diferentes algoritmos:\n",
    "    - Modelos lineales: Regresión Logística\n",
    "    - Ensambles: Random Forest, Gradient Boosting, XGBoost\n",
    "- Optimizar hiperparámetros mediante validación cruzada\n",
    "\n",
    "3. Evaluación de Modelos\n",
    "- Utilizar métricas apropiadas para detección de fraude: AUC-ROC, Precisión, Recall, F1-Score\n",
    "- Análisis de costos de falsos positivos vs. falsos negativos\n",
    "- Evaluar el rendimiento en diferentes segmentos para verificar equidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
